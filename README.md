# Titanic
Titanic - Machine Learning from Disaster
This project aims to predict the survival of passengers on the Titanic using machine learning algorithms. The Titanic dataset was obtained from Kaggle and contains information on the passengers such as their age, gender, class, and ticket fare, as well as whether they survived or not.

The project involved several steps such as data exploration, data cleaning, feature engineering, model selection, hyperparameter tuning, and evaluation. The main goal was to build models that could accurately predict the survival of passengers on the Titanic using the given features.

The project was implemented using Python programming language and several popular libraries such as NumPy, Pandas, Matplotlib, Scikit-learn, and XGBoost.

The following files are included in this project:

1-train.csv - the training dataset used to train the models
2-test.csv - the test dataset used to evaluate the models
3-titanic_survival_prediction.ipynb - a Jupyter notebook containing the code and documentation of the project
4-submission_rf.csv - the submission file for the random forest model
5-submission_vc_hard.csv - the submission file for the hard voting classifier model
6-submission_vc_soft.csv - the submission file for the soft voting classifier model
7-submission_vc_all.csv - the submission file for the voting classifier with all base estimators model
8-submission_vc_xgb2.csv - the submission file for the XGBoost model
To run the Jupyter notebook, you need to have Python 3 and the required libraries installed. You can use the following command to install the libraries:
-- pip install numpy pandas matplotlib scikit-learn xgboost
Once you have installed the libraries, you can run the Jupyter notebook using the following command:
-- jupyter notebook titanic_survival_prediction.ipynb
The notebook contains detailed documentation and explanations of the code used in the project. You can follow the notebook step-by-step to reproduce the results or modify the code to experiment with different models or parameters.

The submission files contain the predicted survival of passengers on the test dataset for each model. These files can be submitted to Kaggle to evaluate the performance of the models and compare them with other submissions.

Overall, this project provides a good introduction to machine learning and data science concepts such as data preprocessing, feature engineering, model selection, and hyperparameter tuning. It also demonstrates how to use popular Python libraries to implement machine learning algorithms and generate predictions for real-world problems.



